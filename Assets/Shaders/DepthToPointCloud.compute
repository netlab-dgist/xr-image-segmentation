// Compute Shader for extracting PointCloud from Depth + RGB
// Supports both legacy Mask-based extraction and full-frame RGBD extraction (QuestCameraKit style)

#pragma kernel ExtractPointCloud
#pragma kernel DebugMask
#pragma kernel GeneratePointCloud

// Input Textures
Texture2DArray<float> _DepthTexture;
Texture2D<float4> _ColorTexture; // New: Direct RGB Texture Input

SamplerState sampler_DepthTexture;
SamplerState sampler_ColorTexture;

// Input Buffers (Legacy)
StructuredBuffer<float> _MaskBuffer;
StructuredBuffer<uint> _RGBBuffer;

// Output Buffers
RWStructuredBuffer<float4> _PositionBuffer;  // xyz, w=1 (valid)
RWStructuredBuffer<uint> _ColorBuffer;       // RGBA packed
RWStructuredBuffer<int> _CounterBuffer;      // [0]=pointCount, ...

// Uniforms
float4 _CameraIntrinsics;     // fx, fy, cx, cy
float4 _CameraPosition;       // Camera world position
float4x4 _CameraRotation;     // Camera rotation matrix (world space)
float4 _BBoxParams;           // Legacy: centerX, centerY, width, height

float _ConfidenceThreshold;
int _RGBWidth;
int _RGBHeight;
int _DepthWidth;
int _DepthHeight;
int _MaxPoints;
float _MinDepth;
float _MaxDepth;

float4 _DepthZBufferParams;   // x=invDepthFactor, y=depthOffset
float4x4 _DepthReprojMatrix;  // World to Depth clip space
int _SubSampleFactor;         // 1 = all pixels, 2 = 1/4 pixels, etc.

// --- Helper Functions ---

// Convert mask coordinate to RGB pixel coordinate (Legacy)
int2 MaskToRGBPixel(float maskX, float maskY, float4 bbox, int rgbW, int rgbH)
{
    float scaleYoloToRgb = (float)rgbW / 640.0;
    float normX = maskX / 160.0;
    float normY = maskY / 160.0;
    float posInYoloX = bbox.x - bbox.z * 0.5 + normX * bbox.z;
    float posInYoloY = bbox.y - bbox.w * 0.5 + normY * bbox.w;
    int pixelX = (int)(posInYoloX * scaleYoloToRgb + rgbW * 0.5);
    int pixelY = (int)(rgbH * 0.5 - posInYoloY * scaleYoloToRgb);
    return int2(clamp(pixelX, 0, rgbW - 1), clamp(pixelY, 0, rgbH - 1));
}

// Parallax-Corrected Depth Sampling
float SampleDepthIterative(float3 rayOrigin, float3 rayDir)
{
    float currentDepth = 1.0; 
    for(int i = 0; i < 3; i++)
    {
        float3 estimatedWorldPos = rayOrigin + rayDir * currentDepth;
        float4 depthClip = mul(_DepthReprojMatrix, float4(estimatedWorldPos, 1.0));
        float2 depthNDC = depthClip.xy / depthClip.w;
        float2 depthUV = depthNDC * 0.5 + 0.5;

        if (depthUV.x < 0.0 || depthUV.x > 1.0 || depthUV.y < 0.0 || depthUV.y > 1.0)
            return -1.0;

        int dx = (int)(depthUV.x * (_DepthWidth - 1));
        int dy = (int)(depthUV.y * (_DepthHeight - 1));
        float rawDepth = _DepthTexture[int3(dx, dy, 0)];
        float depthNdc = rawDepth * 2.0 - 1.0;
        float sampledDepth = _DepthZBufferParams.x / (depthNdc + _DepthZBufferParams.y);
        currentDepth = sampledDepth;
    }
    return currentDepth;
}

// --- Kernels ---

// 1. Legacy Mask-based Extraction
[numthreads(8, 8, 1)]
void ExtractPointCloud(uint3 id : SV_DispatchThreadID)
{
    if (id.x >= 160 || id.y >= 160) return;
    int flippedY = 159 - (int)id.y;
    int maskIdx = flippedY * 160 + id.x;
    float maskVal = _MaskBuffer[maskIdx];

    if (maskVal < _ConfidenceThreshold) return;

    InterlockedAdd(_CounterBuffer[1], 1);
    float maskX = (float)id.x;
    float maskY = (float)flippedY;
    int2 rgbPixel = MaskToRGBPixel(maskX, maskY, _BBoxParams, _RGBWidth, _RGBHeight);

    float fx = _CameraIntrinsics.x;
    float fy = _CameraIntrinsics.y;
    float cx = _CameraIntrinsics.z;
    float cy = _CameraIntrinsics.w;
    int androidY = _RGBHeight - 1 - rgbPixel.y;

    float3 dirInCamera = float3((rgbPixel.x - cx) / fx, (androidY - cy) / fy, 1.0);
    dirInCamera = normalize(dirInCamera);
    float3 dirInWorld = mul((float3x3)_CameraRotation, dirInCamera);

    float depthMeters = SampleDepthIterative(_CameraPosition.xyz, dirInWorld);

    if (depthMeters < _MinDepth || depthMeters > _MaxDepth)
    {
        InterlockedAdd(_CounterBuffer[3], 1);
        return;
    }

    float3 worldPos = _CameraPosition.xyz + dirInWorld * depthMeters;
    int idx;
    InterlockedAdd(_CounterBuffer[0], 1, idx);
    if (idx >= _MaxPoints) return;

    _PositionBuffer[idx] = float4(worldPos, 1.0);
    
    // Legacy buffer read
    int rgbIdx = rgbPixel.y * _RGBWidth + rgbPixel.x;
    if (rgbIdx >= 0 && rgbIdx < _RGBWidth * _RGBHeight)
        _ColorBuffer[idx] = _RGBBuffer[rgbIdx];
    else
        _ColorBuffer[idx] = 0xFFFFFFFF;
}

// 2. Legacy Debug Mask
[numthreads(8, 8, 1)]
void DebugMask(uint3 id : SV_DispatchThreadID)
{
    // ... (Use same logic as ExtractPointCloud mostly)
}

// 3. New Full-Frame Generation (QuestCameraKit Style)
[numthreads(8, 8, 1)]
void GeneratePointCloud(uint3 id : SV_DispatchThreadID)
{
    // id.xy corresponds to RGB texture coordinates
    // Apply subsampling
    uint2 pixelCoords = id.xy * _SubSampleFactor;

    if (pixelCoords.x >= (uint)_RGBWidth || pixelCoords.y >= (uint)_RGBHeight)
        return;

    // 1. Sample RGB Color
    float4 color = _ColorTexture.Load(int3(pixelCoords, 0));
    
    // Convert float4 color to packed uint
    uint r = (uint)(color.r * 255.0);
    uint g = (uint)(color.g * 255.0);
    uint b = (uint)(color.b * 255.0);
    uint a = (uint)(color.a * 255.0);
    uint packedColor = r | (g << 8) | (b << 16) | (a << 24);

    // 2. Calculate Ray Direction
    float fx = _CameraIntrinsics.x;
    float fy = _CameraIntrinsics.y;
    float cx = _CameraIntrinsics.z;
    float cy = _CameraIntrinsics.w;
    
    // Adjust Y for Android Camera coordinates if needed (usually Top-Left origin)
    // Unity textures are Bottom-Left origin.
    // If intrinsics 'cy' is from Top-Left, we need to convert our y.
    // Assuming intrinsics are standard Computer Vision (Top-Left):
    int androidY = _RGBHeight - 1 - pixelCoords.y; 

    float3 dirInCamera = float3(
        (pixelCoords.x - cx) / fx,
        (androidY - cy) / fy,
        1.0
    );
    dirInCamera = normalize(dirInCamera);
    float3 dirInWorld = mul((float3x3)_CameraRotation, dirInCamera);

    // 3. Sample Depth with Parallax Correction
    float depthMeters = SampleDepthIterative(_CameraPosition.xyz, dirInWorld);

    // 4. Validate Depth
    if (depthMeters < _MinDepth || depthMeters > _MaxDepth)
        return;

    // 5. Compute World Position
    float3 worldPos = _CameraPosition.xyz + dirInWorld * depthMeters;

    // 6. Append to Buffer
    int idx;
    InterlockedAdd(_CounterBuffer[0], 1, idx);
    if (idx >= _MaxPoints) return;

    _PositionBuffer[idx] = float4(worldPos, 1.0);
    _ColorBuffer[idx] = packedColor;
}